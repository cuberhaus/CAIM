In stochastic optimal control, change of measure arguments have been crucial for stochastic analysis.
Such an approach is often called static reduction in dynamic team theory (or decentralized stochastic
control) and has been an effective method for establishing existence and approximation results
for optimal policies. In this paper, we place such static reductions into three categories: (i)
those that are policy-independent (as those introduced by Witsenhausen), (ii) those that are policy-dependent
(as those introduced by Ho and Chu for partially nested dynamic teams), and (iii) those that we will
refer to as static measurements with control-sharing reduction (where the measurements are static
although control actions are shared according to the partially nested information structure).
For the first type, we show that there is a bijection between person-by-person optimal (globally
optimal) policies of dynamic teams and their policy-independent static reductions. For the second
type, although there is a bijection between globally optimal policies of dynamic teams with partially
nested information structures and their static reductions, in general there is no bijection between
person-by-person optimal policies of dynamic teams and their policy-dependent static reductions.
We also establish a stronger negative result concerning stationary solutions. We present sufficient
conditions under which bijection relationships hold. Under static measurements with control-sharing
reduction, connections between optimality concepts can be established under relaxed conditions.
An implication is a convexity characterization of dynamic team problems under static measurements
with control-sharing reduction. Finally, we introduce multi-stage refinements of such reductions.
Part II of the paper addresses similar issues in the context of stochastic dynamic games, where further
subtleties arise. 