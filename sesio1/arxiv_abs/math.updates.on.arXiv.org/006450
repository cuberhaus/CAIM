We introduce a new method to approximate integrals $\int_{\mathbb{R}^d} f(\boldsymbol{x}) \,
\mathrm{d} \boldsymbol{x}$ which simply scales lattice rules from the unit cube $[0,1]^d$ to properly
sized boxes on $\mathbb{R}^d$, hereby achieving higher-order convergence that matches the smoothness
of the integrand function $f$ in a certain Sobolev space of dominating mixed smoothness. Our method
only assumes that we can evaluate the integrand function $f$ and does not assume a particular density
nor the ability to sample from it. In particular, for the theoretical analysis we show a new result
that the method of adding Bernoulli polynomials to a function to make it "periodic" on a box without
changing its integral value over the box, is equivalent to an orthogonal projection from a well chosen
Sobolev space of dominating mixed smoothness to an associated periodic Sobolev space of the same
dominating mixed smoothness, which we call a Korobov space. We note that the Bernoulli polynomial
method is often not used because of its excessive computational complexity and also here we only
make use of it in our theoretical analysis. We show that our new method of applying scaled lattice
rules to increasing boxes can be interpreted as orthogonal projections with decreasing projection
error. Such a method would not work on the unit cube since then the committed error caused by non-periodicity
of the integrand would be constant, but for integration on the Euclidean space we can use the certain
decay towards zero when the boxes grow. Hence we can bound the truncation error as well as the projection
error and show higher-order convergence in applying scaled lattice rules for integration on Euclidean
space. We illustrate our theoretical analysis by numerical experiments which confirm our findings.
