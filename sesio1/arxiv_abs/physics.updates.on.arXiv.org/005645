Recently, computational modeling has shifted towards the use of deep learning, and other data-driven
modeling frameworks. Although this shift in modeling holds promise in many applications like design
optimization and real-time control by lowering the computational burden, training deep learning
models needs a huge amount of data. This big data is not always available for scientific problems
and leads to poorly generalizable data-driven models. This gap can be furnished by leveraging information
from physics-based models. Exploiting prior knowledge about the problem at hand, this study puts
forth a concatenated neural network approach to build more tailored, effective, and efficient
machine learning models. For our analysis, without losing its generalizability and modularity,
we focus on the development of predictive models for laminar and turbulent boundary layer flows.
In particular, we combine the self-similarity solution and power-law velocity profile (low-fidelity
models) with the noisy data obtained either from experiments or computational fluid dynamics simulations
(high-fidelity models) through a concatenated neural network. We illustrate how the knowledge
from these simplified models results in reducing uncertainties associated with deep learning
models. The proposed framework produces physically consistent models that attempt to achieve
better generalization than data-driven models obtained purely based on data. While we demonstrate
our framework for a problem relevant to fluid mechanics, its workflow and principles can be adopted
for many scientific problems where empirical models are prevalent. In line with grand demands in
novel physics-guided machine learning principles, this work builds a bridge between extensive
physics-based theories and data-driven modeling paradigms and paves the way for using hybrid modeling
approaches for next-generation digital twin technologies. 