Tumor segmentation in oncological PET is challenging, a major reason being the partial-volume
effects that arise due to low system resolution and finite voxel size. The latter results in tissue-fraction
effects, i.e. voxels contain a mixture of tissue classes. Conventional segmentation methods are
typically designed to assign each voxel in the image as belonging to a certain tissue class. Thus,
these methods are inherently limited in modeling tissue-fraction effects. To address the challenge
of accounting for partial-volume effects, and in particular, tissue-fraction effects, we propose
a Bayesian approach to tissue-fraction estimation for oncological PET segmentation. Specifically,
this Bayesian approach estimates the posterior mean of fractional volume that the tumor occupies
within each voxel of the image. The proposed method, implemented using a deep-learning-based technique,
was first evaluated using clinically realistic 2-D simulation studies with known ground truth,
in the context of segmenting the primary tumor in PET images of patients with lung cancer. The evaluation
studies demonstrated that the method accurately estimated the tumor-fraction areas and significantly
outperformed widely used conventional PET segmentation methods, including a U-net-based method,
on the task of segmenting the tumor. In addition, the proposed method was relatively insensitive
to partial-volume effects and yielded reliable tumor segmentation for different clinical-scanner
configurations. The method was then evaluated using clinical images of patients with stage IIB/III
non-small cell lung cancer from ACRIN 6668/RTOG 0235 multi-center clinical trial. Here, the results
showed that the proposed method significantly outperformed all other considered methods and yielded
accurate tumor segmentation on patient images with Dice similarity coefficient (DSC) of 0.82 (95
% CI: [0.78, 0.86]). 