Galactic bars are prominent dynamical structures within disk galaxies whose size, formation time,
strength, and pattern speed influence the dynamical evolution of their hosts galaxies. Yet, their
formation and evolution in a cosmological context is not well understood, as cosmological simulation
studies have been limited by the classic trade off between simulation volume and resolution. Here
we analyze barred disk galaxies in the cosmological magneto-hydrodynamical simulation TNG50
and quantitatively compare the distributions of bar size and pattern speed to those from MaNGA observations
at $z=0$. TNG50 galaxies are selected to match the stellar mass and size distributions of observed
galaxies, to account for observational selection effects. We find that the high-resolution of
TNG50 yields bars with a wide range of pattern speeds (including those with $\geq 40~\mathrm{km}\,\mathrm{s}^{-1}$\,$\mathrm{kpc}^{-1}$)
and a mean value of $\sim36~\mathrm{km}\,\mathrm{s}^{-1}\,\mathrm{kpc}$ consistent with observations
within $6\,\mathrm{km}\,\mathrm{s}^{-1}$\,$\mathrm{kpc}^{-1}$, in contrast with previous
lower-resolution cosmological simulations that produced bars that were too slow. We find, however,
that bars in TNG50 are on average $\sim 35\%$ shorter than observed, although this discrepancy may
partly reflect remaining inconsistencies in the simulation-data comparison. This leads to higher
values of $\mathcal{R} = R_\mathrm{corot}/R_\mathrm{bar}$ in TNG50, but points to simulated
bars being `too short' rather than `too slow'. After repeating the analysis on the lower-resolution
run of the same simulation (with the same physical model), we qualitatively reproduce the results
obtained in previous studies: this implies that, along with physical model variations, numerical
resolution effects may explain the previously found `slowness' of simulated bars. 