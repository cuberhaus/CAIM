In this work, we investigate the reliability of spectral synthesis methods in the estimation of
the mean stellar age and metallicity, addressing the question of which signal-to-noise ratios
(S/N) are needed to determine these quantities. To address this problem we used simulated spectra
containing stellar and nebular emission, reproducing the evolution of a galaxy for a constant and
exponentially declining star formation law. The spectra have been degraded to different S/N and
analysed with three different spectral synthesis codes: FADO, STARLIGHT, and STECKMAP assuming
similar fitting set-ups and the same spectral bases. For S/N > 5 all tools considered show a large
diversity in the results. FADO and STARLIGHT find median differences in light-weighted mean stellar
ages of ~0.1 dex, while STECKMAP shows a higher value of ~0.2 dex. For S/N > 50 the median differences
in FADO are ~0.03 dex (~7%), a factor 3 and 4 lower than the 0.08 dex (~20%) and 0.11 dex (~30%) obtained
from STARLIGHT and STECKMAP, respectively. Our results indicate that phases of high specific star
formation rate (sSFR) in galaxies require analysis tools that do not neglect the nebular continuum
emission in the fitting process, since purely stellar models would have strong problems in the estimation
of star formation history, even in presence of high S/N spectra. The median values of these differences
are of the order of 7% (FADO), 20% (STARLIGHT), and 30% (STECKMAP) for light-weighted quantities,
and 20% (FADO), 60% (STARLIGHT), and 20% (STECKMAP) for mass-weighted quantities. That implies
a severe overestimation of the mass-to-light ratio and stellar mass, even in the presence of a mild
contribution from the nebular continuum. Our work underlines the importance of a self-consistent
treatment of nebular emission, which is the only route towards a reliable determination of the assembly
of any high-sSFR galaxy. 