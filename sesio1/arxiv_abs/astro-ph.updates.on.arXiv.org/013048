We carry out a comparative analysis of the relation between the mass of supermassive black holes
(BHs) and the stellar mass of their host galaxies at $0.2<z<1.7$ using well-matched observations
and multiple state-of-the-art simulations (e.g., Massive Black II, Horizon-AGN, Illustris,
TNG and a semi-analytic model). The observed sample consists of 646 uniformly-selected SDSS quasars
($0.2 < z < 0.8$) and 32 broad-line active galactic nuclei (AGNs; $1.2<z<1.7$) with imaging from
Hyper Suprime-Cam (HSC) for the former and Hubble Space Telescope (HST) for the latter. We first
add realistic observational uncertainties to the simulation data and then construct a simulated
sample in the same manner as the observations. Over the full redshift range, our analysis demonstrates
that all simulations predict a level of intrinsic scatter of the scaling relations comparable to
the observations which appear to agree with the dispersion of the local relation. Regarding the
mean relation, Horizon-AGN and TNG are in closest agreement with the observations at low and high
redshift ($z\sim$ 0.2 and 1.5, respectively) while the other simulations show subtle differences
within the uncertainties. For insight into the physics involved, the scatter of the scaling relation,
seen in the SAM, is reduced by a factor of two and closer to the observations after adopting a new feedback
model that considers the geometry of the AGN outflow. The consistency in the dispersion with redshift
in our analysis supports the importance of both quasar- and radio-mode feedback prescriptions
in the simulations. Finally, we highlight the importance of increasing the sensitivity (e.g.,
using the James Webb Space Telescope), thereby pushing to lower masses and minimizing biases due
to selection effects. 