Precise radial velocity (PRV) surveys are important for the search of Earth analogs around nearby
bright stars. Such planets induce a small stellar reflex motion with RV amplitude of $\sim$10 cm/s.
Detecting such a small RV signal poses important challenges to instrumentation, data analysis,
and the precision of astrophysical models to mitigate stellar jitter. In this work, we investigate
an important component in the PRV error budget - the spectral contamination from the Earth's atmosphere
(tellurics). We characterize the effects of telluric absorption on the RV precision and quantify
its contribution to the RV budget over time and across a wavelength range of 350 nm - 2.5$\mu$m. We
investigate the effectiveness in mitigating tellurics using simulated spectra of a solar twin
star with telluric contamination over a year's worth of observations, and we extracted the RVs using
two commonly adopted algorithms: dividing out a telluric model before performing cross-correlation
or Forward Modeling the observed spectrum incorporating a telluric model. We assume various degrees
of cleanness in removing the tellurics, including mimicking the lack of accurate knowledge of the
telluric lines by using a mismatched line profile to model the "observed" tellurics. We conclude
that the RV errors caused by telluric absorption can be suppressed to close to or even below the photon-limited
precision in the optical region, especially in the blue, around 1-10 cm/s. At red through near-infrared
wavelengths, however, the residuals of tellurics can induce an RV error on the m/s level even under
the most favorable assumptions for telluric removal, leading to significant systematic noise
in the RV time series and periodograms. If the red-optical or near-infrared becomes critical in
the mitigation of stellar activity, systematic errors from tellurics can be eliminated with a space
mission such as EarthFinder. 