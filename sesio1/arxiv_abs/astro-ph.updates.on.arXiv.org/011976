The solar chromosphere is heated to temperatures higher than predicted by radiative equilibrium.
This excess heating is greater in active regions where the magnetic field is stronger. We aim to investigate
the magnetic topology associated with an area of enhanced millimeter (mm) brightness temperatures
in a solar active region mapped by the Atacama Large Millimeter/submillimeter Array (ALMA) using
spectropolarimetric co-observations with the 1-m Swedish Solar Telescope (SST). We used Milne-Eddington
inversions, nonlocal thermodynamic equilibrium (non-LTE) inversions, and a magnetohydrostatic
extrapolation to obtain constraints on the three-dimensional stratification of temperature,
magnetic field, and radiative energy losses. We compared the observations to a snapshot of a magnetohydrodynamics
simulation and investigate the formation of the thermal continuum at 3 mm using contribution functions.
We find enhanced heating rates in the upper chromosphere of up to $\sim 5\rm\,kW\,m^{-2}$, where
small-scale emerging loops interact with the overlying magnetic canopy leading to current sheets
as shown by the magnetic field extrapolation. Our estimates are about a factor of two higher than
canonical values, but they are limited by the ALMA spatial resolution ($\sim 1.2^{\prime\prime}$).
Band 3 brightness temperatures reach about $\sim10^{4}\,$K in the region, and the transverse magnetic
field strength inferred from the non-LTE inversions is on the order of $\sim 500\,$G in the chromosphere.
We are able to quantitatively reproduce many of the observed features, including the integrated
radiative losses in our numerical simulation. We conclude that the heating is caused by dissipation
in current sheets. However, the simulation shows a complex stratification in the flux emergence
region where distinct layers may contribute significantly to the emission in the mm continuum.
