Active regions on the photosphere of a star have been the major obstacle for detecting Earth-like
exoplanets using the radial velocity (RV) method. A commonly employed solution for addressing
stellar activity is to assume a linear relationship between the RV observations and the activity
indicators along the entire time series, and then remove the estimated contribution of activity
from the variation in RV data (overall correction method). However, since active regions evolve
on the photosphere over time, correlations between the RV observations and the activity indicators
will correspondingly be anisotropic. We present an approach that recognizes the RV locations where
the correlations between the RV and the activity indicators significantly change in order to better
account for variations in RV caused by stellar activity. The proposed approach uses a general family
of statistical breakpoint methods, often referred to as change point detection (CPD) algorithms;
several implementations of which are available in R and python. A thorough comparison is made between
the breakpoint-based approach and the overall correction method. To ensure wide representativity,
we use measurements from real stars that have different levels of stellar activity and whose spectra
have different signal-to-noise ratios. When the corrections for stellar activity are applied
separately to each temporal segment identified by the breakpoint method, the corresponding residuals
in the RV time series are typically much smaller than those obtained by the overall correction method.
Consequently, the generalized Lomb-Scargle periodogram contains a smaller number of peaks caused
by active regions. The CPD algorithm is particularly effective when focusing on active stars with
long time series, such as alpha Cen B. 