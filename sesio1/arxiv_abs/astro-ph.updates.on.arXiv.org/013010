The multi-TeV energy region of the cosmic-ray spectra has been recently explored by direct detection
experiments that used calorimetric techniques to measure the energy of the cosmic particles. Interesting
spectral features have been observed in both all-electron and nuclei spectra. However, the interpretation
of the results is compromised by the disagreements between the data obtained from the various experiments,
that are not reconcilable with the quoted experimental uncertainties. Understanding the reason
for the discrepancy among the measurements is of fundamental importance in view of the forthcoming
high-energy cosmic-ray experiments planned for space, as well as for the correct interpretation
of the available results. The purpose of this work is to investigate the possibility that a systematic
effect may derive from the non-proportionality of the light response of inorganic crystals, typically
used in high-energy calorimetry due to their excellent energy-resolution performance. The main
reason for the non-proportionality of the crystals is that scintillation light yield depends on
ionisation density. Experimental data obtained with ion beams were used to characterize the light
response of various scintillator materials. The obtained luminous efficiencies were used as input
of a Monte Carlo simulation to perform a comparative study of the effect of the light-yield non-proportionality
on the detection of high-energy electromagnetic and hadronic showers. The result of this study
indicates that, if the calorimeter response is calibrated by using the energy deposit of minimum
ionizing particles, the measured shower energy might be affected by a significant systematic shift,
at the level of few percent, whose sign and magnitude depend specifically on the type of scintillator
material used. 