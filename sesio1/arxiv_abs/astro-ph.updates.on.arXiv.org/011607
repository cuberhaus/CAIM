The Latin American Giant Observatory (LAGO) is a distributed cosmic ray observatory at a regional
scale in Latin America, by deploying a large network of Water Cherenkov detectors (WCD) and other
astroparticle detectors in a wide range of latitudes from Antarctica to M\'exico, and altitudes
from sea level to more than 5500 m a.s.l. Detectors telemetry, atmospherics conditions and flux
of secondary particles at the ground are measured with extreme detail at each LAGO site by using our
own-designed hardware and firmware (ACQUA). To combine and analyse all these data, LAGO developed
ANNA, our data analysis framework. Additionally, ARTI, a complete framework of simulations designed
to simulate the expected signals at our detectors coming from primary cosmic rays entering the Earth
atmosphere, allowing a precise characterization of the sites in realistic atmospheric, geomagnetic
and detector conditions. As the measured and synthetic data started to flow, we are facing challenging
scenarios given a large amount of data emerging, performed on a diversity of detectors and computing
architectures and e-infrastructures. These data need to be transferred, analyzed, catalogued,
preserved, and provided for internal and public access and data-mining under an open e-science
environment. In this work, we present the implementation of ARTI at the EOSC-Synergy cloud-based
services as the first example of LAGO' frameworks that will follow the FAIR principles for provenance,
data curation and re-using of data. For this, we calculate the flux of secondary particles expected
in up to 1 week at detector level for all the 26 LAGO, and the 1-year flux of high energy secondaries
expected at the ANDES Underground Laboratory and other sites. Therefore, we show how this development
can help not only LAGO but other data-intensive cosmic rays observatories, muography experiments
and underground laboratories. 