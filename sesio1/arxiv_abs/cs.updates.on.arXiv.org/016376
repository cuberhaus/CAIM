Reopened bugs can degrade the overall quality of a software system since they require unnecessary
rework by developers. Moreover, reopened bugs also lead to a loss of trust in the end-users regarding
the quality of the software. Thus, predicting bugs that might be reopened could be extremely helpful
for software developers to avoid rework. Prior studies on reopened bug prediction focus only on
three open source projects (i.e., Apache, Eclipse, and OpenOffice) to generate insights. We observe
that one out of the three projects (i.e., Apache) has a data leak issue -- the bug status of reopened
was included as training data to predict reopened bugs. In addition, prior studies used an outdated
prediction model pipeline (i.e., with old techniques for constructing a prediction model) to predict
reopened bugs. Therefore, we revisit the reopened bugs study on a large scale dataset consisting
of 47 projects tracked by JIRA using the modern techniques such as SMOTE, permutation importance
together with 7 different machine learning models. We study the reopened bugs using a mixed methods
approach (i.e., both quantitative and qualitative study). We find that: 1) After using an updated
reopened bug prediction model pipeline, only 34% projects give an acceptable performance with
AUC >= 0.7. 2) There are four major reasons for a bug getting reopened, that is, technical (i.e., patch/integration
issues), documentation, human (i.e., due to incorrect bug assessment), and reasons not shown in
the bug reports. 3) In projects with an acceptable AUC, 94% of the reopened bugs are due to patch issues
(i.e., the usage of an incorrect patch) identified before bug reopening. Our study revisits reopened
bugs and provides new insights into developer's bug reopening activities. 