The topic of comprehensibility of machine-learned theories has recently drawn increasing attention.
Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data
based on abduction and induction techniques. Learned theories are represented in the form of rules
as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first
evidence of a measurable increase in human comprehension based on machine-learned logic rules
for simple classification tasks. In a later study, it was found that the presentation of machine-learned
explanations to humans can produce both beneficial and harmful effects in the context of game learning.
We continue our investigation of comprehensibility by examining the effects of the ordering of
concept presentations on human comprehension. In this work, we examine the explanatory effects
of curriculum order and the presence of machine-learned explanations for sequential problem-solving.
We show that 1) there exist tasks A and B such that learning A before B has a better human comprehension
with respect to learning B before A and 2) there exist tasks A and B such that the presence of explanations
when learning A contributes to improved human comprehension when subsequently learning B. We propose
a framework for the effects of sequential teaching on comprehension based on an existing definition
of comprehensibility and provide evidence for support from data collected in human trials. Empirical
results show that sequential teaching of concepts with increasing complexity a) has a beneficial
effect on human comprehension and b) leads to human re-discovery of divide-and-conquer problem-solving
strategies, and c) studying machine-learned explanations allows adaptations of human problem-solving
strategy with better performance. 