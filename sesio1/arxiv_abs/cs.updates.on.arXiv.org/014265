Object detection is a fundamental task in computer vision. While approaches for axis-aligned bounding
box detection have made substantial progress in recent years, they perform poorly on oriented objects
which are common in several real-world scenarios such as aerial view imagery and security camera
footage. In these cases, a large part of a predicted bounding box will, undesirably, cover non-object
related areas. Therefore, oriented object detection has emerged with the aim of generalizing object
detection to arbitrary orientations. This enables a tighter fit to oriented objects, leading to
a better separation of bounding boxes especially in case of dense object distributions. The vast
majority of the work in this area has focused on complex two-stage anchor-based approaches. Anchors
act as priors on the bounding box shape and require attentive hyper-parameter fine-tuning on a per-dataset
basis, increased model size, and come with computational overhead. In this work, we present DAFNe:
A Dense one-stage Anchor-Free deep Network for oriented object detection. As a one-stage model,
DAFNe performs predictions on a dense grid over the input image, being architecturally simpler
and faster, as well as easier to optimize than its two-stage counterparts. Furthermore, as an anchor-free
model, DAFNe reduces the prediction complexity by refraining from employing bounding box anchors.
Moreover, we introduce an orientation-aware generalization of the center-ness function for arbitrarily
oriented bounding boxes to down-weight low-quality predictions and a center-to-corner bounding
box prediction strategy that improves object localization performance. DAFNe improves the prediction
accuracy over the previous best one-stage anchor-free model results on DOTA 1.0 by 4.65% mAP, setting
the new state-of-the-art results by achieving 76.95% mAP. 