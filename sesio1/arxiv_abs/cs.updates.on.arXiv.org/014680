Convolutional neural networks (CNNs) are the current state-of-the-art meta-algorithm for volumetric
segmentation of medical data, for example, to localize COVID-19 infected tissue on computer tomography
scans or the detection of tumour volumes in magnetic resonance imaging. A key limitation of 3D CNNs
on voxelised data is that the memory consumption grows cubically with the training data resolution.
Occupancy networks (O-Nets) are an alternative for which the data is represented continuously
in a function space and 3D shapes are learned as a continuous decision boundary. While O-Nets are
significantly more memory efficient than 3D CNNs, they are limited to simple shapes, are relatively
slow at inference, and have not yet been adapted for 3D semantic segmentation of medical data. Here,
we propose Occupancy Networks for Semantic Segmentation (OSS-Nets) to accurately and memory-efficiently
segment 3D medical data. We build upon the original O-Net with modifications for increased expressiveness
leading to improved segmentation performance comparable to 3D CNNs, as well as modifications for
faster inference. We leverage local observations to represent complex shapes and prior encoder
predictions to expedite inference. We showcase OSS-Net's performance on 3D brain tumour and liver
segmentation against a function space baseline (O-Net), a performance baseline (3D residual U-Net),
and an efficiency baseline (2D residual U-Net). OSS-Net yields segmentation results similar to
the performance baseline and superior to the function space and efficiency baselines. In terms
of memory efficiency, OSS-Net consumes comparable amounts of memory as the function space baseline,
somewhat more memory than the efficiency baseline and significantly less than the performance
baseline. As such, OSS-Net enables memory-efficient and accurate 3D semantic segmentation that
can scale to high resolutions. 