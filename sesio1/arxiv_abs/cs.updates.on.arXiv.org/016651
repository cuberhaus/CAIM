Attaching attributes (such as color, shape, state, action) to object categories is an important
computer vision problem. Attribute prediction has seen exciting recent progress and is often formulated
as a multi-label classification problem. Yet significant challenges remain in: 1) predicting
diverse attributes over multiple categories, 2) modeling attributes-category dependency, 3)
capturing both global and local scene context, and 4) predicting attributes of objects with low
pixel-count. To address these issues, we propose a novel multi-category attribute prediction
deep architecture named GlideNet, which contains three distinct feature extractors. A global
feature extractor recognizes what objects are present in a scene, whereas a local one focuses on
the area surrounding the object of interest. Meanwhile, an intrinsic feature extractor uses an
extension of standard convolution dubbed Informed Convolution to retrieve features of objects
with low pixel-count. GlideNet uses gating mechanisms with binary masks and its self-learned category
embedding to combine the dense embeddings. Collectively, the Global-Local-Intrinsic blocks
comprehend the scene's global context while attending to the characteristics of the local object
of interest. Finally, using the combined features, an interpreter predicts the attributes, and
the length of the output is determined by the category, thereby removing unnecessary attributes.
GlideNet can achieve compelling results on two recent and challenging datasets -- VAW and CAR --
for large-scale attribute prediction. For instance, it obtains more than 5\% gain over state of
the art in the mean recall (mR) metric. GlideNet's advantages are especially apparent when predicting
attributes of objects with low pixel counts as well as attributes that demand global context understanding.
Finally, we show that GlideNet excels in training starved real-world scenarios. 