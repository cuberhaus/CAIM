Active inference is a state-of-the-art framework for modelling the brain that explains a wide range
of mechanisms such as habit formation, dopaminergic discharge and curiosity. However, recent
implementations suffer from an exponential complexity class when computing the prior over all
the possible policies up to the time horizon. Fountas et al (2020) used Monte Carlo tree search to
address this problem, leading to very good results in two different tasks. Additionally, Champion
et al (2021a) proposed a tree search approach based on (temporal) structure learning. This was enabled
by the development of a variational message passing approach to active inference, which enables
compositional construction of Bayesian networks for active inference. However, this message
passing tree search approach, which we call branching-time active inference (BTAI), has never
been tested empirically. In this paper, we present an experimental study of BTAI in the context of
a maze solving agent. In this context, we show that both improved prior preferences and deeper search
help mitigate the vulnerability to local minima. Then, we compare BTAI to standard active inference
(AcI) on a graph navigation task. We show that for small graphs, both BTAI and AcI successfully solve
the task. For larger graphs, AcI exhibits an exponential (space) complexity class, making the approach
intractable. However, BTAI explores the space of policies more efficiently, successfully scaling
to larger graphs. Then, BTAI was compared to the POMCP algorithm on the frozen lake environment.
The experiments suggest that BTAI and the POMCP algorithm accumulate a similar amount of reward.
Also, we describe when BTAI receives more rewards than the POMCP agent, and when the opposite is true.
Finally, we compared BTAI to the approach of Fountas et al (2020) on the dSprites dataset, and we discussed
the pros and cons of each approach. 