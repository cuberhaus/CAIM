Data privacy is critical in instilling trust and empowering the societal pacts of modern technology-driven
democracies. Unfortunately, it is under continuous attack by overreaching or outright oppressive
governments, including some of the world's oldest democracies. Increasingly-intrusive anti-encryption
laws severely limit the ability of standard encryption to protect privacy. New defense mechanisms
are needed. Plausible deniability (PD) is a powerful property, enabling users to hide the existence
of sensitive information in a system under direct inspection by adversaries. Popular encrypted
storage systems such as TrueCrypt and other research efforts have attempted to also provide plausible
deniability. Unfortunately, these efforts have often operated under less well-defined assumptions
and adversarial models. Careful analyses often uncover not only high overheads but also outright
security compromise. Further, our understanding of adversaries, the underlying storage technologies,
as well as the available plausible deniable solutions have evolved dramatically in the past two
decades. The main goal of this work is to systematize this knowledge. It aims to: - identify key PD
properties, requirements, and approaches; - present a direly-needed unified framework for evaluating
security and performance; - explore the challenges arising from the critical interplay between
PD and modern system layered stacks; - propose a new "trace-oriented" PD paradigm, able to decouple
security guarantees from the underlying systems and thus ensure a higher level of flexibility and
security independent of the technology stack. This work is meant also as a trusted guide for system
and security practitioners around the major challenges in understanding, designing, and implementing
plausible deniability into new or existing systems. 