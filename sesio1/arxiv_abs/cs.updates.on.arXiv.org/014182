We present a DevIce-to-System Performance EvaLuation (DISPEL) workflow that integrates transistor
and interconnect modeling, parasitic extraction, standard cell library characterization, logic
synthesis, cell placement and routing, and timing analysis to evaluate system-level performance
of new CMOS technologies. As the impact of parasitic resistances and capacitances continues to
increase with dimensional downscaling, component-level optimization alone becomes insufficient,
calling for a holistic assessment and optimization methodology across the boundaries between
devices, interconnects, circuits, and systems. The physical implementation flow in DISPEL enables
realistic analysis of complex wires and vias in VLSI systems and their impact on the chip power, speed,
and area, which simple circuit simulations cannot capture. To demonstrate the use of DISPEL, a 32-bit
commercial processor core is implemented using theoretical n-type MoS2 and p-type Black Phosphorous
(BP) planar FETs at a projected 5-nm node, and the performance is benchmarked against Si FinFETs.
While the superior gate control of the MoS2/BP FETs can theoretically provide 51% reduction in the
iso-frequency energy consumption, the actual performance can be greatly limited by the source/drain
contact resistances. With the large amount of data generated by DISPEL, a neural-network is trained
to predict the key performance metrics of the 32-bit processor core using the characteristics of
transistors and interconnects as the input features without the need to go through the time-consuming
physical implementation flow. The machine learning algorithms show great potentials as a means
for evaluation and optimization of new CMOS technologies and identifying the most significant
technology design parameters. 