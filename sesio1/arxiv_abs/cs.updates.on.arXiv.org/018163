State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or speech recognition
(ASR)) are constructed and trained end-to-end as an atomic unit. No component of the model can be
(re-)used without the others. We describe LegoNN, a procedure for building encoder-decoder architectures
with decoder modules that can be reused across various MT and ASR tasks, without the need for any fine-tuning.
To achieve reusability, the interface between each encoder and decoder modules is grounded to a
sequence of marginal distributions over a discrete vocabulary pre-defined by the model designer.
We present two approaches for ingesting these marginals; one is differentiable, allowing the flow
of gradients across the entire network, and the other is gradient-isolating. To enable portability
of decoder modules between MT tasks for different source languages and across other tasks like ASR,
we introduce a modality agnostic encoder which consists of a length control mechanism to dynamically
adapt encoders' output lengths in order to match the expected input length range of pre-trained
decoders. We present several experiments to demonstrate the effectiveness of LegoNN models: a
trained language generation LegoNN decoder module from German-English (De-En) MT task can be reused
with no fine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT tasks to match
or beat respective baseline models. When fine-tuned towards the target task for few thousand updates,
our LegoNN models improved the Ro-En MT task by 1.5 BLEU points, and achieved 12.5% relative WER reduction
for the Europarl ASR task. Furthermore, to show its extensibility, we compose a LegoNN ASR model
from three modules -- each has been learned within different end-to-end trained models on three
different datasets -- boosting the WER reduction to 19.5%. 