This paper concerns the research problem of point cloud registration to find the rigid transformation
to optimally align the source point set with the target one. Learning robust point cloud registration
models with deep neural networks has emerged as a powerful paradigm, offering promising performance
in predicting the global geometric transformation for a pair of point sets. Existing methods firstly
leverage an encoder to regress a latent shape embedding, which is then decoded into a shape-conditioned
transformation via concatenation-based conditioning. However, different regions of a 3D shape
vary in their geometric structures which makes it more sense that we have a region-conditioned transformation
instead of the shape-conditioned one. In this paper we present a \underline{R}egion-\underline{A}ware
point cloud \underline{R}egistration, denoted as RAR, to predict transformation for pairwise
point sets in the self-supervised learning fashion. More specifically, we develop a novel region-aware
decoder (RAD) module that is formed with an implicit neural region representation parameterized
by neural networks. The implicit neural region representation is learned with a self-supervised
3D shape reconstruction loss without the need for region labels. Consequently, the region-aware
decoder (RAD) module guides the training of the region-aware transformation (RAT) module and region-aware
weight (RAW) module, which predict the transforms and weights for different regions respectively.
The global geometric transformation from source point set to target one is then formed by the weighted
fusion of region-aware transforms. Compared to the state-of-the-art approaches, our experiments
show that our RAR achieves superior registration performance over various benchmark datasets
(e.g. ModelNet40). 