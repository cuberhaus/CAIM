Autonomous racing is becoming popular for academic and industry researchers as a test for general
autonomous driving by pushing perception, planning, and control algorithms to their limits. While
traditional control methods such as MPC are capable of generating an optimal control sequence at
the edge of the vehicles physical controllability, these methods are sensitive to the accuracy
of the modeling parameters. This paper presents TC-Driver, a RL approach for robust control in autonomous
racing. In particular, the TC-Driver agent is conditioned by a trajectory generated by any arbitrary
traditional high-level planner. The proposed TC-Driver addresses the tire parameter modeling
inaccuracies by exploiting the heuristic nature of RL while leveraging the reliability of traditional
planning methods in a hierarchical control structure. We train the agent under varying tire conditions,
allowing it to generalize to different model parameters, aiming to increase the racing capabilities
of the system in practice. The proposed RL method outperforms a non-learning-based MPC with a 2.7
lower crash ratio in a model mismatch setting, underlining robustness to parameter discrepancies.
In addition, the average RL inference duration is 0.25 ms compared to the average MPC solving time
of 11.5 ms, yielding a nearly 40-fold speedup, allowing for complex control deployment in computationally
constrained devices. Lastly, we show that the frequently utilized end-to-end RL architecture,
as a control policy directly learned from sensory input, is not well suited to model mismatch robustness
nor track generalization. Our realistic simulations show that TC-Driver achieves a 6.7 and 3-fold
lower crash ratio under model mismatch and track generalization settings, while simultaneously
achieving lower lap times than an end-to-end approach, demonstrating the viability of TC-driver
to robust autonomous racing. 