The evolution of preferences that account for other agents' fitness, or other-regarding preferences,
has been modeled with the "indirect approach" to evolutionary game theory. Under the indirect evolutionary
approach, agents make decisions by optimizing a subjective utility function. Evolution may select
for subjective preferences that differ from the fitness function, and in particular, subjective
preferences for increasing or reducing other agents' fitness. However, indirect evolutionary
models typically artificially restrict the space of strategies that agents might use (assuming
that agents always play a Nash equilibrium under their subjective preferences), and dropping this
restriction can undermine the finding that other-regarding preferences are selected for. Can
the indirect evolutionary approach still be used to explain the apparent existence of other-regarding
preferences, like altruism, in humans? We argue that it can, by accounting for the costs associated
with the complexity of strategies, giving (to our knowledge) the first account of the relationship
between strategy complexity and the evolution of preferences. Our model formalizes the intuition
that agents face tradeoffs between the low cognitive cost of simple strategies within a single context,
and the ability of more complex (subjective utility-maximizing) strategies to interpolate across
contexts. For a single game, these penalties lead to selection for a simple fixed-action strategy,
but across games, when there is a sufficiently large penalty on a strategy's number of context-specific
parameters, a strategy of maximizing subjective (other-regarding) utility is stable again. Overall,
our analysis provides a more nuanced picture of when other-regarding preferences will evolve.
