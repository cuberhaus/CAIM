Detection Transformer (DETR) and Deformable DETR have been proposed to eliminate the need for many
hand-designed components in object detection while demonstrating good performance as previous
complex hand-crafted detectors. However, their performance on Video Object Detection (VOD) has
not been well explored. In this paper, we present TransVOD, the first end-to-end video object detection
system based on spatial-temporal Transformer architectures. The first goal of this paper is to
streamline the pipeline of VOD, effectively removing the need for many hand-crafted components
for feature aggregation, e.g., optical flow model, relation networks. Besides, benefited from
the object query design in DETR, our method does not need complicated post-processing methods such
as Seq-NMS. In particular, we present a temporal Transformer to aggregate both the spatial object
queries and the feature memories of each frame. Our temporal transformer consists of two components:
Temporal Query Encoder (TQE) to fuse object queries, and Temporal Deformable Transformer Decoder
(TDTD) to obtain current frame detection results. These designs boost the strong baseline deformable
DETR by a significant margin (3%-4% mAP) on the ImageNet VID dataset. Then, we present two improved
versions of TransVOD including TransVOD++ and TransVOD Lite. The former fuses object-level information
into object query via dynamic convolution while the latter models the entire video clips as the output
to speed up the inference time. We give detailed analysis of all three models in the experiment part.
In particular, our proposed TransVOD++ sets a new state-of-the-art record in terms of accuracy
on ImageNet VID with 90.0% mAP. Our proposed TransVOD Lite also achieves the best speed and accuracy
trade-off with 83.7% mAP while running at around 30 FPS on a single V100 GPU device. Code and models
will be available for further research. 