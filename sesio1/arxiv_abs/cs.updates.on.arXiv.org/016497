The adaptive processing of structured data is a long-standing research topic in machine learning
that investigates how to automatically learn a mapping from a structured input to outputs of various
nature. Recently, there has been an increasing interest in the adaptive processing of graphs, which
led to the development of different neural network-based methodologies. In this thesis, we take
a different route and develop a Bayesian Deep Learning framework for graph learning. The dissertation
begins with a review of the principles over which most of the methods in the field are built, followed
by a study on graph classification reproducibility issues. We then proceed to bridge the basic ideas
of deep learning for graphs with the Bayesian world, by building our deep architectures in an incremental
fashion. This framework allows us to consider graphs with discrete and continuous edge features,
producing unsupervised embeddings rich enough to reach the state of the art on several classification
tasks. Our approach is also amenable to a Bayesian nonparametric extension that automatizes the
choice of almost all model's hyper-parameters. Two real-world applications demonstrate the efficacy
of deep learning for graphs. The first concerns the prediction of information-theoretic quantities
for molecular simulations with supervised neural models. After that, we exploit our Bayesian models
to solve a malware-classification task while being robust to intra-procedural code obfuscation
techniques. We conclude the dissertation with an attempt to blend the best of the neural and Bayesian
worlds together. The resulting hybrid model is able to predict multimodal distributions conditioned
on input graphs, with the consequent ability to model stochasticity and uncertainty better than
most works. Overall, we aim to provide a Bayesian perspective into the articulated research field
of deep learning for graphs. 