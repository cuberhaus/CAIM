Cognitive computational neuroscience (CCN) suggests that to gain a mechanistic understanding
of brain function, hypothesis driven experiments should be accompanied by biologically plausible
computational models. This novel research paradigm offers a way from alchemy to chemistry, in auditory
neuroscience. With a special focus on tinnitus - as the prime example of auditory phantom perception
- we review recent work at the intersection of artificial intelligence, psychology, and neuroscience,
foregrounding the idea that experiments will yield mechanistic insight only when employed to test
formal or computational models. This view challenges the popular notion that tinnitus research
is primarily data limited, and that producing large, multi-modal, and complex data-sets, analyzed
with advanced data analysis algorithms, will lead to fundamental insights into how tinnitus emerges.
We conclude that two fundamental processing principles - being ubiquitous in the brain - best fit
to a vast number of experimental results and therefore provide the most explanatory power: predictive
coding as a top-down, and stochastic resonance as a complementary bottom-up mechanism. Furthermore,
we argue that even though contemporary artificial intelligence and machine learning approaches
largely lack biological plausibility, the models to be constructed will have to draw on concepts
from these fields; since they provide a formal account of the requisite computations that underlie
brain function. Nevertheless, biological fidelity will have to be addressed, allowing for testing
possible treatment strategies in silico, before application in animal or patient studies. This
iteration of computational and empirical studies may help to open the "black boxes" of both machine
learning and the human brain. 