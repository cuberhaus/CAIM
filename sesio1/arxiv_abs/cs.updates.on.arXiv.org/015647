Recent advancements in Electroencephalography (EEG) sensor technologies and signal processing
algorithms have paved the way for further evolution of Brain Computer Interfaces (BCI). When it
comes to Signal Processing (SP) for BCI, there has been a surge of interest on Steady-State motion-Visual
Evoked Potentials (SSmVEP), where motion stimulation is utilized to address key issues associated
with conventional light-flashing/flickering. Such benefits, however, come with the price of
having less accuracy and less Information Transfer Rate (ITR). In this regard, the paper focuses
on the design of a novel SSmVEP paradigm without using resources such as trial time, phase, and/or
number of targets to enhance the ITR. The proposed design is based on the intuitively pleasing idea
of integrating more than one motion within a single SSmVEP target stimuli, simultaneously. To elicit
SSmVEP, we designed a novel and innovative dual frequency aggregated modulation paradigm, referred
to as the Dual Frequency Aggregated steady-state motion Visual Evoked Potential (DF-SSmVEP),
by concurrently integrating "Radial Zoom" and "Rotation" motions in a single target without increasing
the trial length. Compared to conventional SSmVEPs, the proposed DF-SSmVEP framework consists
of two motion modes integrated and shown simultaneously each modulated by a specific target frequency.
The paper also develops a specific unsupervised classification model, referred to as the Bifold
Canonical Correlation Analysis (BCCA), based on two motion frequencies per target. The proposed
DF-SSmVEP is evaluated based on a real EEG dataset and the results corroborate its superiority.
The proposed DF-SSmVEP outperforms its counterparts and achieved an average ITR of 30.7 +/- 1.97
and an average accuracy of 92.5 +/- 2.04. 