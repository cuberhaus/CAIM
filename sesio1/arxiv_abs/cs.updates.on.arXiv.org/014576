Label noise is pervasive in real-world datasets, which encodes wrong correlation patterns and
impairs the generalization of deep neural networks (DNNs). It is critical to find efficient ways
to detect the corrupted patterns. Current methods primarily focus on designing robust training
techniques to prevent DNNs from memorizing corrupted patterns. This approach has two outstanding
caveats: 1) applying this approach to each individual dataset would often require customized training
processes; 2) as long as the model is trained with noisy supervisions, overfitting to corrupted
patterns is often hard to avoid, leading to performance drop in detection. In this paper, given good
representations, we propose a universally applicable and training-free solution to detect noisy
labels. Intuitively, good representations help define ``neighbors'' of each training instance,
and closer instances are more likely to share the same clean label. Based on the neighborhood information,
we propose two methods: the first one uses ``local voting" via checking the noisy label consensuses
of nearby representations. The second one is a ranking-based approach that scores each instance
and filters out a guaranteed number of instances that are likely to be corrupted, again using only
representations. Given good (but possibly imperfect) representations that are commonly available
in practice, we theoretically analyze how they affect the local voting and provide guidelines for
tuning neighborhood size. We also prove the worst-case error bound for the ranking-based method.
Experiments with both synthetic and real-world label noise demonstrate our training-free solutions
are consistently and significantly improving over most of the training-based baselines. Code
is available at github.com/UCSC-REAL/SimiRep. 