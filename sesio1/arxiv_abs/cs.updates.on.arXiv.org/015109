Understanding how activity in neural circuits reshapes following task learning could reveal fundamental
mechanisms of learning. Thanks to the recent advances in neural imaging technologies, high-quality
recordings can be obtained from hundreds of neurons over multiple days or even weeks. However, the
complexity and dimensionality of population responses pose significant challenges for analysis.
Existing methods of studying neuronal adaptation and learning often impose strong assumptions
on the data or model, resulting in biased descriptions that do not generalize. In this work, we use
a variant of deep generative models called - CycleGAN, to learn the unknown mapping between pre-
and post-learning neural activities recorded $\textit{in vivo}$. We develop an end-to-end pipeline
to preprocess, train and evaluate calcium fluorescence signals, and a procedure to interpret the
resulting deep learning models. To assess the validity of our method, we first test our framework
on a synthetic dataset with known ground-truth transformation. Subsequently, we applied our method
to neural activities recorded from the primary visual cortex of behaving mice, where the mice transition
from novice to expert-level performance in a visual-based virtual reality experiment. We evaluate
model performance on generated calcium signals and their inferred spike trains. To maximize performance,
we derive a novel approach to pre-sort neurons such that convolutional-based networks can take
advantage of the spatial information that exists in neural activities. In addition, we incorporate
visual explanation methods to improve the interpretability of our work and gain insights into the
learning process as manifested in the cellular activities. Together, our results demonstrate
that analyzing neuronal learning processes with data-driven deep unsupervised methods holds
the potential to unravel changes in an unbiased way. 