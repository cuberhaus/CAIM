During the COVID-19 pandemic, health-related misinformation and harmful content shared online
had a significant adverse effect on society. To mitigate this adverse effect, mainstream social
media platforms employed soft moderation interventions (i.e., warning labels) on potentially
harmful posts. Despite the recent popularity of these moderation interventions, we lack empirical
analyses aiming to uncover how these warning labels are used in the wild, particularly during challenging
times like the COVID-19 pandemic. In this work, we analyze the use of warning labels on TikTok, focusing
on COVID-19 videos. First, we construct a set of 26 COVID-19 related hashtags, then we collect 41K
videos that include those hashtags in their description. Second, we perform a quantitative analysis
on the entire dataset to understand the use of warning labels on TikTok. Then, we perform an in-depth
qualitative study, using thematic analysis, on 222 COVID-19 related videos to assess the content
and the connection between the content and the warning labels. Our analysis shows that TikTok broadly
applies warning labels on TikTok videos, likely based on hashtags included in the description.
More worrying is the addition of COVID-19 warning labels on videos where their actual content is
not related to COVID-19 (23% of the cases in a sample of 143 English videos that are not related to COVID-19).
Finally, our qualitative analysis on a sample of 222 videos shows that 7.7% of the videos share misinformation/harmful
content and do not include warning labels, 37.3% share benign information and include warning labels,
and that 35% of the videos that share misinformation/harmful content (and need a warning label)
are made for fun. Our study demonstrates the need to develop more accurate and precise soft moderation
systems, especially on a platform like TikTok that is extremely popular among people of younger
age. 