Supervised learning for semantic segmentation requires a large number of labeled samples, which
is difficult to obtain in the field of remote sensing. Self-supervised learning (SSL), can be used
to solve such problems by pre-training a general model with a large number of unlabeled images and
then fine-tuning it on a downstream task with very few labeled samples. Contrastive learning is
a typical method of SSL that can learn general invariant features. However, most existing contrastive
learning methods are designed for classification tasks to obtain an image-level representation,
which may be suboptimal for semantic segmentation tasks requiring pixel-level discrimination.
Therefore, we propose a global style and local matching contrastive learning network (GLCNet)
for remote sensing image semantic segmentation. Specifically, 1) the global style contrastive
learning module is used to better learn an image-level representation, as we consider that style
features can better represent the overall image features. 2) The local features matching contrastive
learning module is designed to learn representations of local regions, which is beneficial for
semantic segmentation. The experimental results show that our method mostly outperforms SOTA
self-supervised methods and the ImageNet pre-training method. Specifically, with 1\% annotation
from the original dataset, our approach improves Kappa by 6\% on the ISPRS Potsdam dataset relative
to the existing baseline. Moreover, our method outperforms supervised learning methods when there
are some differences between the datasets of upstream tasks and downstream tasks. Since SSL could
directly learn the essential characteristics of data from unlabeled data, which is easy to obtain
in the remote sensing field, this may be of great significance for tasks such as global mapping. The
source code is available at https://github.com/GeoX-Lab/G-RSIM. 