Artificial Intelligence (AI) systems based solely on neural networks or symbolic computation
present a representational complexity challenge. While minimal representations can produce
behavioral outputs like locomotion or simple decision-making, more elaborate internal representations
might offer a richer variety of behaviors. We propose that these issues can be addressed with a computational
approach we call meta-brain models. Meta-brain models are embodied hybrid models that include
layered components featuring varying degrees of representational complexity. We will propose
combinations of layers composed using specialized types of models. Rather than using a generic
black box approach to unify each component, this relationship mimics systems like the neocortical-thalamic
system relationship of the Mammalian brain, which utilizes both feedforward and feedback connectivity
to facilitate functional communication. Importantly, the relationship between layers can be
made anatomically explicit. This allows for structural specificity that can be incorporated into
the model's function in interesting ways. We will propose several types of layers that might be functionally
integrated into agents that perform unique types of tasks, from agents that simultaneously perform
morphogenesis and perception, to agents that undergo morphogenesis and the acquisition of conceptual
representations simultaneously. Our approach to meta-brain models involves creating models
with different degrees of representational complexity, creating a layered meta-architecture
that mimics the structural and functional heterogeneity of biological brains, and an input/output
methodology flexible enough to accommodate cognitive functions, social interactions, and adaptive
behaviors more generally. We will conclude by proposing next steps in the development of this flexible
and open-source approach. 