Online platforms have a wealth of data, run countless experiments and use industrial-scale algorithms
to optimize user experience. Despite this, many users seem to regret the time they spend on these
platforms. One possible explanation is misaligned incentives: platforms are not optimizing for
user happiness. We suggest the problem runs deeper, transcending the specific incentives of any
particular platform, and instead stems from a mistaken revealed-preference assumption: To understand
what users want, platforms look at what users do. Yet research has demonstrated, and personal experience
affirms, that we often make choices in the moment that are inconsistent with what we actually want.
In this work, we develop a model of media consumption where users have inconsistent preferences.
We consider an altruistic platform which simply wants to maximize user utility, but only observes
user engagement. We show how our model of users' preference inconsistencies produces phenomena
that are familiar from everyday experience, but difficult to capture in traditional user interaction
models. A key ingredient in our model is a formulation for how platforms determine what to show users:
they optimize over a large set of potential content (the content manifold) parametrized by underlying
features of the content. Whether improving engagement improves user welfare depends on the direction
of movement in the content manifold: for certain directions of change, increasing engagement makes
users less happy, while in other directions, increasing engagement makes users happier. We characterize
the structure of content manifolds for which increasing engagement fails to increase user utility.
By linking these effects to abstractions of platform design choices, our model thus creates a theoretical
framework and vocabulary in which to explore interactions between design, behavioral science,
and social media. 