Using only global image-class labels, weakly-supervised learning methods, such as class activation
mapping, allow training CNNs to jointly classify an image, and locate regions of interest associated
with the predicted class. However, without any guidance at the pixel level, such methods may yield
inaccurate regions. This problem is known to be more challenging with histology images than with
natural ones, since objects are less salient, structures have more variations, and foreground
and background regions have stronger similarities. Therefore, computer vision methods for visual
interpretation of CNNs may not directly apply. In this paper, a simple yet efficient method based
on a composite loss is proposed to learn information from the fully negative samples (i.e., samples
without positive regions), and thereby reduce false positives/negatives. Our new loss function
contains two complementary terms: the first exploits positive evidence collected from the CNN
classifier, while the second leverages the fully negative samples from training data. In particular,
a pre-trained CNN is equipped with a decoder that allows refining the regions of interest. The CNN
is exploited to collect both positive and negative evidence at the pixel level to train the decoder.
Our method called NEGEV benefits from the fully negative samples that naturally occur in the data,
without any additional supervision signals beyond image-class labels. Extensive experiments
show that our proposed method can substantial outperform related state-of-art methods on GlaS
(public benchmark for colon cancer), and Camelyon16 (patch-based benchmark for breast cancer
using three different backbones). Our results highlight the benefits of using both positive and
negative evidence, the first obtained from a classifier, and the other naturally available in datasets.
