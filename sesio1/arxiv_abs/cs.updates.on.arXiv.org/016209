Existing CNNs-based salient object detection (SOD) heavily depends on the large-scale pixel-level
annotations, which is labor-intensive, time-consuming, and expensive. By contrast, the sparse
annotations become appealing to the salient object detection community. However, few efforts
are devoted to learning salient object detection from sparse annotations, especially in the remote
sensing field. In addition, the sparse annotation usually contains scanty information, which
makes it challenging to train a well-performing model, resulting in its performance largely lagging
behind the fully-supervised models. Although some SOD methods adopt some prior cues to improve
the detection performance, they usually lack targeted discrimination of object boundaries and
thus provide saliency maps with poor boundary localization. To this end, in this paper, we propose
a novel weakly-supervised salient object detection framework to predict the saliency of remote
sensing images from sparse scribble annotations. To implement it, we first construct the scribble-based
remote sensing saliency dataset by relabelling an existing large-scale SOD dataset with scribbles,
namely S-EOR dataset. After that, we present a novel scribble-based boundary-aware network (SBA-Net)
for remote sensing salient object detection. Specifically, we design a boundary-aware module
(BAM) to explore the object boundary semantics, which is explicitly supervised by the high-confidence
object boundary (pseudo) labels generated by the boundary label generation (BLG) module, forcing
the model to learn features that highlight the object structure and thus boosting the boundary localization
of objects. Then, the boundary semantics are integrated with high-level features to guide the salient
object detection under the supervision of scribble labels. 