Melody extraction is a vital music information retrieval task among music researchers for its potential
applications in education pedagogy and the music industry. Melody extraction is a notoriously
challenging task due to the presence of background instruments. Also, often melodic source exhibits
similar characteristics to that of the other instruments. The interfering background accompaniment
with the vocals makes extracting the melody from the mixture signal much more challenging. Until
recently, classical signal processing-based melody extraction methods were quite popular among
melody extraction researchers. The ability of the deep learning models to model large-scale data
and the ability of the models to learn automatic features by exploiting spatial and temporal dependencies
inspired many researchers to adopt deep learning models for melody extraction. In this paper, an
attempt has been made to review the up-to-date data-driven deep learning approaches for melody
extraction from polyphonic music. The available deep models have been categorized based on the
type of neural network used and the output representation they use for predicting melody. Further,
the architectures of the 25 melody extraction models are briefly presented. The loss functions
used to optimize the model parameters of the melody extraction models are broadly categorized into
four categories and briefly describe the loss functions used by various melody extraction models.
Also, the various input representations adopted by the melody extraction models and the parameter
settings are deeply described. A section describing the explainability of the block-box melody
extraction deep neural networks is included. The performance of 25 melody extraction methods is
compared. The possible future directions to explore/improve the melody extraction methods are
also presented in the paper. 