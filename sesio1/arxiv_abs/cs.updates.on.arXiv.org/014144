Convolutional Neural Networks (ConvNets) at present achieve remarkable performance in image
classification tasks. However, current ConvNets cannot guarantee the capabilities of the mammalian
visual systems such as invariance to contrast and illumination changes. Some ideas to overcome
the illumination and contrast variations usually have to be tuned manually and tend to fail when
tested with other types of data degradation. In this context, we present a new bio-inspired {entry}
layer, M6, which detects low-level geometric features (lines, edges, and orientations) which
are similar to patterns detected by the V1 visual cortex. This new trainable layer is capable of coping
with image classification even with large contrast variations. The explanation for this behavior
is the monogenic signal geometry, which represents each pixel value in a 3D space using quaternions,
a fact that confers a degree of explainability to the networks. We compare M6 with a conventional
convolutional layer (C) and a deterministic quaternion local phase layer (Q9). The experimental
setup {is designed to evaluate the robustness} of our M6 enriched ConvNet model and includes three
architectures, four datasets, three types of contrast degradation (including non-uniform haze
degradations). The numerical results reveal that the models with M6 are the most robust in front
of any kind of contrast variations. This amounts to a significant enhancement of the C models, which
usually have reasonably good performance only when the same training and test degradation are used,
except for the case of maximum degradation. Moreover, the Structural Similarity Index Measure
(SSIM) is used to analyze and explain the robustness effect of the M6 feature maps under any kind of
contrast degradations. 