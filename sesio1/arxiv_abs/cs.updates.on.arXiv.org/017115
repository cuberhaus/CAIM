The deep learning revolution incited by the 2012 Alexnet paper has been transformative for the field
of computer vision. Many problems which were severely limited using classical solutions are now
seeing unprecedented success. The rapid proliferation of deep learning methods has led to a sharp
increase in their use in consumer and embedded applications. One consequence of consumer and embedded
applications is lossy multimedia compression which is required to engineer the efficient storage
and transmission of data in these real-world scenarios. As such, there has been increased interest
in a deep learning solution for multimedia compression which would allow for higher compression
ratios and increased visual quality. The deep learning approach to multimedia compression, so
called Learned Multimedia Compression, involves computing a compressed representation of an
image or video using a deep network for the encoder and the decoder. While these techniques have enjoyed
impressive academic success, their industry adoption has been essentially non-existent. Classical
compression techniques like JPEG and MPEG are too entrenched in modern computing to be easily replaced.
This dissertation takes an orthogonal approach and leverages deep learning to improve the compression
fidelity of these classical algorithms. This allows the incredible advances in deep learning to
be used for multimedia compression without threatening the ubiquity of the classical methods.
The key insight of this work is that methods which are motivated by first principles, i.e., the underlying
engineering decisions that were made when the compression algorithms were developed, are more
effective than general methods. By encoding prior knowledge into the design of the algorithm, the
flexibility, performance, and/or accuracy are improved at the cost of generality... 