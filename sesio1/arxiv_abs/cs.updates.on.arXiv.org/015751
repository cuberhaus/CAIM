Modern Artificial Intelligence (AI) systems excel at diverse tasks, from image classification
to strategy games, even outperforming humans in many of these domains. After making astounding
progress in language learning in the recent decade, AI systems, however, seem to approach the ceiling
that does not reflect important aspects of human communicative capacities. Unlike human learners,
communicative AI systems often fail to systematically generalize to new data, suffer from sample
inefficiency, fail to capture common-sense semantic knowledge, and do not translate to real-world
communicative situations. Cognitive Science offers several insights on how AI could move forward
from this point. This paper aims to: (1) suggest that the dominant cognitively-inspired AI directions,
based on nativist and symbolic paradigms, lack necessary substantiation and concreteness to guide
progress in modern AI, and (2) articulate an alternative, "grounded", perspective on AI advancement,
inspired by Embodied, Embedded, Extended, and Enactive Cognition (4E) research. I review results
on 4E research lines in Cognitive Science to distinguish the main aspects of naturalistic learning
conditions that play causal roles for human language development. I then use this analysis to propose
a list of concrete, implementable components for building "grounded" linguistic intelligence.
These components include embodying machines in a perception-action cycle, equipping agents with
active exploration mechanisms so they can build their own curriculum, allowing agents to gradually
develop motor abilities to promote piecemeal language development, and endowing the agents with
adaptive feedback from their physical and social environment. I hope that these ideas can direct
AI research towards building machines that develop human-like language abilities through their
experiences with the world. 