Remote communication has rapidly become a part of everyday life in both professional and personal
contexts. However, popular video conferencing applications present limitations in terms of quality
of communication, immersion and social meaning. VR remote communication applications offer a
greater sense of co-presence and mutual sensing of emotions between remote users. Previous research
on these applications has shown that realistic point cloud user reconstructions offer better immersion
and communication as compared to synthetic user avatars. However, photorealistic point clouds
require a large volume of data per frame and are challenging to transmit over bandwidth-limited
networks. Recent research has demonstrated significant improvements to perceived quality by
optimizing the usage of bandwidth based on the position and orientation of the user's viewport with
user-adaptive streaming. In this work, we developed a real-time VR communication application
with an adaptation engine that features tiled user-adaptive streaming based on user behaviour.
The application also supports traditional network adaptive streaming. The contribution of this
work is to evaluate the impact of tiled user-adaptive streaming on quality of communication, visual
quality, system performance and task completion in a functional live VR remote communication system.
We perform a subjective evaluation with 33 users to compare the different streaming conditions
with a neck exercise training task. As a baseline, we use uncompressed streaming requiring ca. 300Mbps
and our solution achieves similar visual quality with tiled adaptive streaming at 14Mbps. We also
demonstrate statistically significant gains to the quality of interaction and improvements to
system performance and CPU consumption with tiled adaptive streaming as compared to the more traditional
network adaptive streaming. 