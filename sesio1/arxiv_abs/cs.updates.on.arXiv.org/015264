As the globally increasing population drives rapid urbanisation in various parts of the world,
there is a great need to deliberate on the future of the cities worth living. In particular, as modern
smart cities embrace more and more data-driven artificial intelligence services, it is worth remembering
that technology can facilitate prosperity, wellbeing, urban livability, or social justice, but
only when it has the right analog complements (such as well-thought out policies, mature institutions,
responsible governance); and the ultimate objective of these smart cities is to facilitate and
enhance human welfare and social flourishing. Researchers have shown that various technological
business models and features can in fact contribute to social problems such as extremism, polarization,
misinformation, and Internet addiction. In the light of these observations, addressing the philosophical
and ethical questions involved in ensuring the security, safety, and interpretability of such
AI algorithms that will form the technological bedrock of future cities assumes paramount importance.
Globally there are calls for technology to be made more humane and human-centered. In this paper,
we analyze and explore key challenges including security, robustness, interpretability, and
ethical (data and algorithmic) challenges to a successful deployment of AI in human-centric applications,
with a particular emphasis on the convergence of these concepts/challenges. We provide a detailed
review of existing literature on these key challenges and analyze how one of these challenges may
lead to others or help in solving other challenges. The paper also advises on the current limitations,
pitfalls, and future directions of research in these domains, and how it can fill the current gaps
and lead to better solutions. We believe such rigorous analysis will provide a baseline for future
research in the domain. 