Recent research is trying to leverage occupants' demand in the building's control loop to consider
individuals' well-being and the buildings' energy savings. To that end, a real-time feedback system
is needed to provide data about occupants' comfort conditions that can be used to control the building's
heating, cooling, and air conditioning (HVAC) system. The emergence of thermal imaging techniques
provides an excellent opportunity for contactless data gathering with no interruption in occupant
conditions and activities. There is increasing attention to infrared thermal camera usage in public
buildings because of their non-invasive quality in reading the human skin temperature. However,
the state-of-the-art methods need additional modifications to become more reliable. To capitalize
potentials and address some existing limitations, new solutions are required to bring a more holistic
view toward non-intrusive thermal scanning by leveraging the benefit of machine learning and image
processing. This research implements an automated approach to collect and register simultaneous
thermal and visual images and read the facial temperature in different regions. This paper also
presents two additional investigations. First, through utilizing IButton wearable thermal sensors
on the forehead area, we investigate the reliability of an in-expensive thermal camera (FLIR Lepton)
in reading the skin temperature. Second, by studying the false-color version of thermal images,
we look into the possibility of non-radiometric thermal images for predicting personalized thermal
comfort. The results shows the strong performance of Random Forest and K-Nearest Neighbor prediction
algorithms in predicting personalized thermal comfort. In addition, we have found that non-radiometric
images can also indicate thermal comfort when the algorithm is trained with larger amounts of data.
