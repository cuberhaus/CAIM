Virtual reality (VR) has seen increased use for training and instruction. Designers can enable
VR users to gain insights into their own performance by visualizing telemetry data from their actions
in VR. Our ability to detect patterns and trends visually suggests the use of data visualization
as a tool for users to identify strategies for improved performance. Typical tasks in VR training
scenarios are manipulation of 3D objects (e.g., for learning how to maintain a jet engine) and navigation
(e.g., to learn the geography of a building or landscape before traveling on-site). In this paper,
we present the results of the RUI VR (84 subjects) and Luddy VR studies (68 subjects), where participants
were divided into experiment and control cohorts. All subjects performed a series of tasks: 44 cube-matching
tasks in RUI VR and 48 navigation tasks through a virtual building in Luddy VR (all divided into two
sets). All Luddy VR subjects used VR gear; RUI VR subjects were divided across three setups: 2D Desktop
(with laptop and mouse), VR Tabletop (in VR, sitting at a table), and VR Standup (in VR, standing).
In an intervention called "Reflective phase," the experiment cohorts were presented with data
visualizations, designed with the Data Visualization Literacy Framework (DVL-FW), of the data
they generated during the first set of tasks before continuing to the second part of the study. For
Luddy VR, we found that experiment users had significantly faster completion times in their second
trial (p = 0.014) while scoring higher in a mid-questionnaire about the virtual building (p = 0.009).
For RUI VR, we found no significant differences for completion time and accuracy between the two
cohorts in the VR setups; however, 2D Desktop subjects in the experiment cohort had significantly
higher rotation accuracy as well as satisfaction (p(rotation) = 0.031, p(satisfaction) = 0.040).
