Artificial intelligence literature suggests that minority and fragile communities in society
can be negatively impacted by machine learning algorithms due to inherent biases in the design process,
which lead to socially exclusive decisions and policies. Faced with similar challenges in dealing
with an increasingly diversified audience, the museum sector has seen changes in theory and practice,
particularly in the areas of representation and meaning-making. While rarity and grandeur used
to be at the centre stage of the early museum practices, folk life and museums' relationships with
the diverse communities they serve become a widely integrated part of the contemporary practices.
These changes address issues of diversity and accessibility in order to offer more socially inclusive
services. Drawing on these changes and reflecting back on the AI world, we argue that the museum experience
provides useful lessons for building AI with socially inclusive approaches, especially in situations
in which both a collection and access to it will need to be curated or filtered, as frequently happens
in search engines, recommender systems and digital libraries. We highlight three principles:
(1) Instead of upholding the value of neutrality, practitioners are aware of the influences of their
own backgrounds and those of others on their work. By not claiming to be neutral but practising cultural
humility, the chances of addressing potential biases can be increased. (2) There should be room
for situational interpretation beyond the stages of data collection and machine learning. Before
applying models and predictions, the contexts in which relevant parties exist should be taken into
account. (3) Community participation serves the needs of communities and has the added benefit
of bringing practitioners and communities together. 