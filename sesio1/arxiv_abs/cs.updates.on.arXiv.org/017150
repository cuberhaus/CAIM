Text matching is a fundamental technique in both information retrieval and natural language processing.
Text matching tasks share the same paradigm that determines the relationship between two given
texts. Evidently, the relationships vary from task to task, e.g. relevance in document retrieval,
semantic alignment in paraphrase identification and answerable judgment in question answering.
However, the essential signals for text matching remain in a finite scope, i.e. exact matching,
semantic matching, and inference matching. Recent state-of-the-art neural text matching models,
e.g. pre-trained language models (PLMs), are hard to generalize to different tasks. It is because
the end-to-end supervised learning on task-specific dataset makes model overemphasize the data
sample bias and task-specific signals instead of the essential matching signals, which ruins the
generalization of model to different tasks. To overcome this problem, we adopt a specialization-generalization
training strategy and refer to it as Match-Prompt. In specialization stage, descriptions of different
matching tasks are mapped to only a few prompt tokens. In generalization stage, text matching model
explores the essential matching signals by being trained on diverse multiple matching tasks. High
diverse matching tasks avoid model fitting the data sample bias on a specific task, so that model
can focus on learning the essential matching signals. Meanwhile, the prompt tokens obtained in
the first step are added to the corresponding tasks to help the model distinguish different task-specific
matching signals. Experimental results on eighteen public datasets show that Match-Prompt can
significantly improve multi-task generalization capability of PLMs in text matching, and yield
better in-domain multi-task, out-of-domain multi-task and new task adaptation performance than
task-specific model. 