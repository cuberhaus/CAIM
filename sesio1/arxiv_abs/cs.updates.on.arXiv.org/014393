The United Nations identified gender equality as a Sustainable Development Goal in 2015, recognizing
the underrepresentation of women in politics as a specific barrier to achieving gender equality.
Political systems around the world experience gender inequality across all levels of elected government
as fewer women run for office than men. This is due in part to online abuse, particularly on social
media platforms like Twitter, where women seeking or in power tend to be targeted with more toxic
maltreatment than their male counterparts. In this paper, we present reflections on ParityBOT
- the first natural language processing-based intervention designed to affect online discourse
for women in politics for the better, at scale. Deployed across elections in Canada, the United States
and New Zealand, ParityBOT was used to analyse and classify more than 12 million tweets directed
at women candidates and counter toxic tweets with supportive ones. From these elections we present
three case studies highlighting the current limitations of, and future research and application
opportunities for, using a natural language processing-based system to detect online toxicity,
specifically with regards to contextually important microaggressions. We examine the rate of
false negatives, where ParityBOT failed to pick up on insults directed at specific high profile
women, which would be obvious to human users. We examine the unaddressed harms of microaggressions
and the potential of yet unseen damage they cause for women in these communities, and for progress
towards gender equality overall, in light of these technological blindspots. This work concludes
with a discussion on the benefits of partnerships between nonprofit social groups and technology
experts to develop responsible, socially impactful approaches to addressing online hate. 