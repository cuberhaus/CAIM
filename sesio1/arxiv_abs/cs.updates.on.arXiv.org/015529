While the English virtual assistants have achieved exciting performance with an enormous amount
of training resources, the needs of non-English-speakers have not been satisfied well. Up to Dec
2021, Alexa, one of the most popular smart speakers around the world, is able to support 9 different
languages [1], while there are thousands of languages in the world, 91 of which are spoken by more
than 10 million people according to statistics published in 2019 [2]. However, training a virtual
assistant in other languages than English is often more difficult, especially for those low-resource
languages. The lack of high-quality training data restricts the performance of models, resulting
in poor user satisfaction. Therefore, we devise an efficient and effective training solution for
multilingual task-orientated dialogue systems, using the same dataset generation pipeline and
end-to-end dialogue system architecture as BiToD[5], which adopted some key design choices for
a minimalistic natural language design where formal dialogue states are used in place of natural
language inputs. This reduces the room for error brought by weaker natural language models, and
ensures the model can correctly extract the essential slot values needed to perform dialogue state
tracking (DST). Our goal is to reduce the amount of natural language encoded at each turn, and the
key parameter we investigate is the number of turns (H) to feed as history to model. We first explore
the turning point where increasing H begins to yield limiting returns on the overall performance.
Then we examine whether the examples a model with small H gets wrong can be categorized in a way for
the model to do few-shot finetuning on. Lastly, will explore the limitations of this approach, and
whether there is a certain type of examples that this approach will not be able to resolve. 