Because of its willingness to share data with academia and industry, Twitter has been the primary
social media platform for scientific research as well as for the consulting of businesses and governments
in the last decade. In recent years, a series of publications have studied and criticized Twitter's
APIs and Twitter has partially adapted its existing data streams. The newest Twitter API for Academic
Research allows to "access Twitter's real-time and historical public data with additional features
and functionality that support collecting more precise, complete, and unbiased datasets." The
main new feature of this API is the possibility of accessing the full archive of all historic Tweets.
In this article, we will take a closer look at the Academic API and will try to answer two questions.
First, are the datasets collected with the Academic API complete? Secondly, since Twitter's Academic
API delivers historic Tweets as represented on Twitter at the time of data collection, we need to
understand how much data is lost over time due to Tweet and account removal from the platform. Our
work shows evidence that Twitter's Academic API can indeed create (almost) complete samples of
Twitter data based on a wide variety of search terms. We also provide evidence that Twitter's data
endpoint v2 delivers better samples than the previously used endpoint v1.1. Furthermore, collecting
Tweets with the Academic API at the time of studying a phenomenon rather than creating local archives
of stored Tweets, allows for a straightforward way of following Twitter's developer agreement.
Finally, we will also discuss technical artifacts and implications of the Academic API. We hope
that our work can add another layer of understanding of Twitter data collections leading to more
reliable studies of human behavior via social media data. 