A key challenge of real-world image super-resolution (SR) is to recover the missing details in low-resolution
(LR) images with complex unknown degradations (e.g., downsampling, noise and compression). Most
previous works restore such missing details in the image space. To cope with the high diversity of
natural images, they either rely on the unstable GANs that are difficult to train and prone to artifacts,
or resort to explicit references from high-resolution (HR) images that are usually unavailable.
In this work, we propose Feature Matching SR (FeMaSR), which restores realistic HR images in a much
more compact feature space. Unlike image-space methods, our FeMaSR restores HR images by matching
distorted LR image {\it features} to their distortion-free HR counterparts in our pretrained HR
priors, and decoding the matched features to obtain realistic HR images. Specifically, our HR priors
contain a discrete feature codebook and its associated decoder, which are pretrained on HR images
with a Vector Quantized Generative Adversarial Network (VQGAN). Notably, we incorporate a novel
semantic regularization in VQGAN to improve the quality of reconstructed images. For the feature
matching, we first extract LR features with an LR encoder consisting of several Swin Transformer
blocks and then follow a simple nearest neighbour strategy to match them with the pretrained codebook.
In particular, we equip the LR encoder with residual shortcut connections to the decoder, which
is critical to the optimization of feature matching loss and also helps to complement the possible
feature matching errors. Experimental results show that our approach produces more realistic
HR images than previous methods. Codes are released at \url{https://github.com/chaofengc/FeMaSR}.
