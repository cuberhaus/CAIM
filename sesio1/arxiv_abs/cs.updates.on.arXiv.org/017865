Deep neural networks such as convolutional neural networks (CNNs) and transformers have achieved
many successes in image classification in recent years. It has been consistently demonstrated
that best practice for image classification is when large deep models can be trained on abundant
labelled data. However there are many real world scenarios where the requirement for large amounts
of training data to get the best performance cannot be met. In these scenarios transfer learning
can help improve performance. To date there have been no surveys that comprehensively review deep
transfer learning as it relates to image classification overall. However, several recent general
surveys of deep transfer learning and ones that relate to particular specialised target image classification
tasks have been published. We believe it is important for the future progress in the field that all
current knowledge is collated and the overarching patterns analysed and discussed. In this survey
we formally define deep transfer learning and the problem it attempts to solve in relation to image
classification. We survey the current state of the field and identify where recent progress has
been made. We show where the gaps in current knowledge are and make suggestions for how to progress
the field to fill in these knowledge gaps. We present a new taxonomy of the applications of transfer
learning for image classification. This taxonomy makes it easier to see overarching patterns of
where transfer learning has been effective and, where it has failed to fulfill its potential. This
also allows us to suggest where the problems lie and how it could be used more effectively. We show
that under this new taxonomy, many of the applications where transfer learning has been shown to
be ineffective or even hinder performance are to be expected when taking into account the source
and target datasets and the techniques used. 