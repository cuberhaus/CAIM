We study the functional task of deep learning image classification models and show that image classification
requires extrapolation capabilities. This suggests that new theories have to be developed for
the understanding of deep learning as the current theory assumes models are solely interpolating,
leaving many questions about them unanswered. We investigate the pixel space and also the feature
spaces extracted from images by trained models (in their hidden layers, including the 64-dimensional
feature space in the last hidden layer of pre-trained residual neural networks), and also the feature
space extracted by wavelets/shearlets. In all these domains, testing samples considerably fall
outside the convex hull of training sets, and image classification requires extrapolation. In
contrast to the deep learning literature, in cognitive science, psychology, and neuroscience,
extrapolation and learning are often studied in tandem. Moreover, many aspects of human visual
cognition and behavior are reported to involve extrapolation. We propose a novel extrapolation
framework for the mathematical study of deep learning models. In our framework, we use the term extrapolation
in this specific way of extrapolating outside the convex hull of training set (in the pixel space
or feature space) but within the specific scope defined by the training data, the same way extrapolation
is defined in many studies in cognitive science. We explain that our extrapolation framework can
provide novel answers to open research problems about deep learning including their over-parameterization,
their training regime, out-of-distribution detection, etc. We also see that the extent of extrapolation
is negligible in learning tasks where deep learning is reported to have no advantage over simple
models. 