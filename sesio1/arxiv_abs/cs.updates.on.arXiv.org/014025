While significant advancements have been made in the generation of deepfakes using deep learning
technologies, its misuse is a well-known issue now. Deepfakes can cause severe security and privacy
issues as they can be used to impersonate a person's identity in a video by replacing his/her face
with another person's face. Recently, a new problem of generating synthesized human voice of a person
is emerging, where AI-based deep learning models can synthesize any person's voice requiring just
a few seconds of audio. With the emerging threat of impersonation attacks using deepfake audios
and videos, a new generation of deepfake detectors is needed to focus on both video and audio collectively.
A large amount of good quality datasets is typically required to capture the real-world scenarios
to develop a competent deepfake detector. Existing deepfake datasets either contain deepfake
videos or audios, which are racially biased as well. Hence, there is a crucial need for creating a
good video as well as an audio deepfake dataset, which can be used to detect audio and video deepfake
simultaneously. To fill this gap, we propose a novel Audio-Video Deepfake dataset (FakeAVCeleb)
that contains not only deepfake videos but also respective synthesized lip-synced fake audios.
We generate this dataset using the current most popular deepfake generation methods. We selected
real YouTube videos of celebrities with four racial backgrounds (Caucasian, Black, East Asian,
and South Asian) to develop a more realistic multimodal dataset that addresses racial bias and further
help develop multimodal deepfake detectors. We performed several experiments using state-of-the-art
detection methods to evaluate our deepfake dataset and demonstrate the challenges and usefulness
of our multimodal Audio-Video deepfake dataset. 