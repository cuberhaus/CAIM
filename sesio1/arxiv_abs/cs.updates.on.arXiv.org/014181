The history of journalism and news diffusion is tightly coupled with the effort to dispel hoaxes,
misinformation, propaganda, unverified rumours, poor reporting, and messages containing hate
and divisions. With the explosive growth of online social media and billions of individuals engaged
with consuming, creating, and sharing news, this ancient problem has surfaced with a renewed intensity
threatening our democracies, public health, and news outlets credibility. This has triggered
many researchers to develop new methods for studying, understanding, detecting, and preventing
fake-news diffusion; as a consequence, thousands of scientific papers have been published in a
relatively short period, making researchers of different disciplines to struggle in search of
open problems and most relevant trends. The aim of this survey is threefold: first, we want to provide
the researchers interested in this multidisciplinary and challenging area with a network-based
analysis of the existing literature to assist them with a visual exploration of papers that can be
of interest; second, we present a selection of the main results achieved so far adopting the network
as an unifying framework to represent and make sense of data, to model diffusion processes, and to
evaluate different debunking strategies. Finally, we present an outline of the most relevant research
trends focusing on the moving target of fake-news, bots, and trolls identification by means of data
mining and text technologies; despite scholars working on computational linguistics and networks
traditionally belong to different scientific communities, we expect that forthcoming computational
approaches to prevent fake news from polluting the social media must be developed using hybrid and
up-to-date methodologies. 