We propose the first near-optimal quantum algorithm for estimating in Euclidean norm the mean of
a vector-valued random variable with finite mean and covariance. Our result aims at extending the
theory of multivariate sub-Gaussian estimators to the quantum setting. Unlike classically, where
any univariate estimator can be turned into a multivariate estimator with at most a logarithmic
overhead in the dimension, no similar result can be proved in the quantum setting. Indeed, Heinrich
ruled out the existence of a quantum advantage for the mean estimation problem when the sample complexity
is smaller than the dimension. Our main result is to show that, outside this low-precision regime,
there is a quantum estimator that outperforms any classical estimator. Our approach is substantially
more involved than in the univariate setting, where most quantum estimators rely only on phase estimation.
We exploit a variety of additional algorithmic techniques such as amplitude amplification, the
Bernstein-Vazirani algorithm, and quantum singular value transformation. Our analysis also
uses concentration inequalities for multivariate truncated statistics. We develop our quantum
estimators in two different input models that showed up in the literature before. The first one provides
coherent access to the binary representation of the random variable and it encompasses the classical
setting. In the second model, the random variable is directly encoded into the phases of quantum
registers. This model arises naturally in many quantum algorithms but it is often incomparable
to having classical samples. We adapt our techniques to these two settings and we show that the second
model is strictly weaker for solving the mean estimation problem. Finally, we describe several
applications of our algorithms, notably in measuring the expectation values of commuting observables
and in the field of machine learning. 