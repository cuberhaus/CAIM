A novel approach for analyzing "classical" alternatives to quantum mechanics for explaining the
statistical results of an EPRB-like experiment is proposed. This perspective is top-down instead
of bottom-up. Rather than beginning with an inequality derivation, a hierarchy of model types is
constructed, each distinguished by appropriately parameterized conditional probabilities.
This hierarchy ranks the "classical" model types in terms of their ability to reproduce QM statistics
or not. The analysis goes beyond the usual consideration of model types that "fall short" (i.e.,
satisfy all of the CHSH inequalities) to ones that are "excessive" (i.e., not only violate CHSH but
even exceed a Tsirelson bound). This approach clearly shows that noncontextuality is the most general
property of an operational model that blocks replication of at least some QM statistical predictions.
Factorizability is naturally revealed to be a special case of noncontextuality. The same is true
for the combination of remote context independence and outcome determinism (RCI+OD). It is noncontextuality
that determines the dividing line between "classical" model instances that satisfy the CHSH inequalities
and those that don't. Outcome deterministic operational models are revealed to be the "building
blocks" of all the rest, including quantum mechanical, noncontextual, and contextual ones. The
set of noncontextual model instances is exactly the convex hull of all 16 RCI+OD model instances,
and furthermore, the set of all model instances, including all QM ones, is equal to the convex hull
of the 256 OD model instances. It is shown that, under a mild assumption, the construction of convex
hulls of finite ensembles of OD model instances is (mathematically) equivalent to the traditional
hidden variables approach. Plots and figures provide visual affirmation of many of the results.
